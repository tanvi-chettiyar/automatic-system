{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/03/12 19:35:37 WARN Utils: Your hostname, tanvi-linux resolves to a loopback address: 127.0.1.1; using 192.168.1.74 instead (on interface wlo1)\n",
      "25/03/12 19:35:37 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/03/12 19:35:38 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .config(\"spark.driver.bindAddress\", \"127.0.0.1\") \\\n",
    "    .config(\"spark.driver.host\", \"127.0.0.1\") \\\n",
    "    .appName(\"YourAppName\") \\\n",
    "    .getOrCreate()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-12 20:05:45.001094\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://127.0.0.1:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.4.4</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>YourAppName</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=YourAppName>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "print(datetime.now())\n",
    "spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'location': {'name': 'Piscataway', 'region': 'New Jersey', 'country': 'USA', 'xxx': 'aaa', 'lat': 40.5527, 'lon': -74.4582, 'tz_id': 'America/New_York', 'localtime_epoch': 1740332071, 'localtime': '2025-02-23 12:34'}, 'current': {'last_updated_epoch': 1740331800, 'last_updated': '2025-02-23 12:30', 'temp_c': 6.7, 'temp_f': 44.1, 'is_day': 1, 'condition': {'text': 'Sunny', 'icon': '//cdn.weatherapi.com/weather/64x64/day/113.png', 'code': 1000}, 'wind_mph': 9.2, 'wind_kph': 14.8, 'wind_degree': 283, 'wind_dir': 'WNW', 'pressure_mb': 1019.0, 'pressure_in': 30.1, 'precip_mm': 0.0, 'precip_in': 0.0, 'humidity': 40, 'cloud': 0, 'feelslike_c': 3.9, 'feelslike_f': 39.0, 'windchill_c': 0.1, 'windchill_f': 32.3, 'heatindex_c': 3.3, 'heatindex_f': 38.0, 'dewpoint_c': -5.6, 'dewpoint_f': 21.9, 'vis_km': 16.0, 'vis_miles': 9.0, 'uv': 3.2, 'gust_mph': 11.1, 'gust_kph': 17.9}, 'forecast': {'forecastday': [{'date': '2025-02-23', 'date_epoch': 1740268800, 'day': {'maxtemp_c': 8.3, 'maxtemp_f': 46.9, 'mintemp_c': -2.9, 'mintemp_f': 26.8, 'avgtemp_c': 1.5, 'avgtemp_f': 34.7, 'maxwind_mph': 9.2, 'maxwind_kph': 14.8, 'totalprecip_mm': 0.0, 'totalprecip_in': 0.0, 'totalsnow_cm': 0.0, 'avgvis_km': 10.0, 'avgvis_miles': 6.0, 'avghumidity': 65, 'daily_will_it_rain': 0, 'daily_chance_of_rain': 0, 'daily_will_it_snow': 0, 'daily_chance_of_snow': 0, 'condition': {'text': 'Partly Cloudy ', 'icon': '//cdn.weatherapi.com/weather/64x64/day/116.png', 'code': 1003}, 'uv': 0.7}, 'hour': [{'time_epoch': 1740286800, 'time': '2025-02-23 00:00', 'temp_c': -1.7, 'temp_f': 29.0, 'is_day': 0, 'condition': {'text': 'Clear ', 'icon': '//cdn.weatherapi.com/weather/64x64/night/113.png', 'code': 1000}, 'wind_mph': 7.4, 'wind_kph': 11.9, 'wind_degree': 239, 'wind_dir': 'WSW', 'pressure_mb': 1022.0, 'pressure_in': 30.19, 'precip_mm': 0.0, 'precip_in': 0.0, 'snow_cm': 0.0, 'humidity': 73, 'cloud': 13, 'feelslike_c': -6.5, 'feelslike_f': 20.3, 'windchill_c': -6.5, 'windchill_f': 20.3, 'heatindex_c': -1.7, 'heatindex_f': 29.0, 'dewpoint_c': -6.0, 'dewpoint_f': 21.2, 'will_it_rain': 0, 'chance_of_rain': 0, 'will_it_snow': 0, 'chance_of_snow': 0, 'vis_km': 10.0, 'vis_miles': 6.0, 'gust_mph': 12.8, 'gust_kph': 20.6, 'uv': 0}, {'time_epoch': 1740369600, 'time': '2025-02-23 23:00', 'temp_c': 2.4, 'temp_f': 36.3, 'is_day': 0, 'condition': {'text': 'Overcast ', 'icon': '//cdn.weatherapi.com/weather/64x64/night/122.png', 'code': 1009}, 'wind_mph': 3.1, 'wind_kph': 5.0, 'wind_degree': 277, 'wind_dir': 'W', 'pressure_mb': 1020.0, 'pressure_in': 30.13, 'precip_mm': 0.0, 'precip_in': 0.0, 'snow_cm': 0.0, 'humidity': 67, 'cloud': 100, 'feelslike_c': 0.3, 'feelslike_f': 32.5, 'windchill_c': 0.3, 'windchill_f': 32.5, 'heatindex_c': 2.4, 'heatindex_f': 36.3, 'dewpoint_c': -3.0, 'dewpoint_f': 26.5, 'will_it_rain': 0, 'chance_of_rain': 0, 'will_it_snow': 0, 'chance_of_snow': 0, 'vis_km': 10.0, 'vis_miles': 6.0, 'gust_mph': 6.2, 'gust_kph': 9.9, 'uv': 0}]}]}}\n"
     ]
    }
   ],
   "source": [
    "# import json \n",
    "\n",
    "# with open(\"/home/tanvi/Documents/GitRepo/automatic-system/etl/data/weather.json\", \"r\") as opfile:\n",
    "#     data = json.load(opfile)\n",
    "\n",
    "# print(data)\n",
    "\n",
    "# with open(\"/home/tanvi/Documents/GitRepo/automatic-system/etl/data/weather_new.json\", \"w\") as f:\n",
    "#     for record in data:\n",
    "#         f.write(json.dumps(record) + \"\\n\")  # âœ… Writes each object on a new line.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.json(\"/home/tanvi/Documents/GitRepo/automatic-system/etl/data/weather/weather_20250312.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- location: struct (nullable = true)\n",
      " |    |-- country: string (nullable = true)\n",
      " |    |-- lat: double (nullable = true)\n",
      " |    |-- localtime: string (nullable = true)\n",
      " |    |-- localtime_epoch: long (nullable = true)\n",
      " |    |-- lon: double (nullable = true)\n",
      " |    |-- name: string (nullable = true)\n",
      " |    |-- region: string (nullable = true)\n",
      " |    |-- tz_id: string (nullable = true)\n",
      "\n",
      "+--------------------+\n",
      "|            location|\n",
      "+--------------------+\n",
      "|{USA, 40.55149841...|\n",
      "+--------------------+\n",
      "\n",
      "+--------------------+\n",
      "|            location|\n",
      "+--------------------+\n",
      "|{USA, 40.55149841...|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()\n",
    "df.show()\n",
    "\n",
    "newdf = df.select(\"location\")\n",
    "newdf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rwxrwxrwx 1 tanvi tanvi 2971 Mar 12 19:29 /home/tanvi/Documents/GitRepo/automatic-system/etl/data/weather_deindent.json\n"
     ]
    }
   ],
   "source": [
    "!ls -ltr /home/tanvi/Documents/GitRepo/automatic-system/etl/data/weather_deindent.json\n",
    "#!chmod 777 /home/tanvi/Documents/GitRepo/automatic-system/etl/data/weather.json\n",
    "#cat /home/tanvi/Documents/GitRepo/automatic-system/etl/data/weather.json | python -m json.tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+\n",
      "| id|           json_data|\n",
      "+---+--------------------+\n",
      "|  1|{\"name\": \"John\", ...|\n",
      "|  2|{\"name\": \"Jane\", ...|\n",
      "+---+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *  # Optional: to use SQL functions like col(), lit(), etc.\n",
    "\n",
    "df.show()\n",
    "\n",
    "# df.createOrReplaceTempView(\"weather_json\")\n",
    "# query = \"SELECT * FROM weather_json\"\n",
    "# result = spark.sql(query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------------------------------------------------------------------+\n",
      "|location                                                                                             |\n",
      "+-----------------------------------------------------------------------------------------------------+\n",
      "|{USA, 40.5527, 2025-02-23 12:34, 1740332071, -74.4582, Piscataway, New Jersey, America/New_York, aaa}|\n",
      "+-----------------------------------------------------------------------------------------------------+\n",
      "\n",
      "+--------------------+\n",
      "|            location|\n",
      "+--------------------+\n",
      "|{USA, 40.5527, 20...|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import get_json_object, col\n",
    "\n",
    "result = df.select( \"location\"\n",
    "    # get_json_object(\"location\", \"$.name\").alias(\"name\") \n",
    "    )\n",
    "\n",
    "result.show(truncate=False)\n",
    "\n",
    "# newdf = df.select(\"location\", \"current\")\n",
    "\n",
    "result.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+\n",
      "| id|           json_data|\n",
      "+---+--------------------+\n",
      "|  1|{\"name\": \"John\", ...|\n",
      "|  2|{\"name\": \"Jane\", ...|\n",
      "+---+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data = [\n",
    "    (\"1\", \"\"\"{\"name\": \"John\", \"age\": 30, \"address\": {\"city\": \"New York\", \"zip\": \"10001\"}, \"phones\": [{\"type\": \"home\", \"number\": \"212-555-1234\"}, {\"type\": \"work\", \"number\": \"646-555-5678\"}]}\"\"\"),\n",
    "    (\"2\", \"\"\"{\"name\": \"Jane\", \"age\": 25, \"address\": {\"city\": \"Boston\", \"zip\": \"02108\"}, \"phones\": [{\"type\": \"mobile\", \"number\": \"617-555-4321\"}]}\"\"\")\n",
    "]\n",
    "\n",
    "samdf = spark.createDataFrame(data, [\"id\", \"json_data\"])\n",
    "\n",
    "# Extract various fields\n",
    "result = samdf.select(\n",
    "    \"id\",\n",
    "    get_json_object(\"json_data\", \"$.name\").alias(\"name\"),\n",
    "    get_json_object(\"json_data\", \"$.age\").alias(\"age\"),\n",
    "    get_json_object(\"json_data\", \"$.address.city\").alias(\"city\"),\n",
    "    get_json_object(\"json_data\", \"$.phones[0].number\").alias(\"first_phone\")\n",
    ")\n",
    "\n",
    "# result.show(truncate=False)\n",
    "samdf.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
