{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "REPE2DaNfFpw",
        "outputId": "44a7ccb6-8243-4788-dafc-e209c3acbf8c"
      },
      "outputs": [],
      "source": [
        "# !pip install psycopg2\n",
        "# !wget -P /content https://jdbc.postgresql.org/download/postgresql-42.2.27.jar\n",
        "# jdbc_driver_path = \"/content/postgresql-42.2.27.jar\"\n",
        "postgres_url = 'jdbc:postgresql://localhost:5432/postgres'\n",
        "jdbc_driver_path = '/opt/spark/jars/postgresql-42.3.1.jar'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C_jUwAJCF9ok"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder \\\n",
        "    .master(\"local[*]\") \\\n",
        "    .config(\"spark.driver.bindAddress\", \"127.0.0.1\") \\\n",
        "    .config(\"spark.driver.host\", \"127.0.0.1\") \\\n",
        "    .config(\"spark.jars\", jdbc_driver_path) \\\n",
        "    .appName(\"WeatherAPIandETL\") \\\n",
        "    .getOrCreate()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "id": "Eq6d-WR0F9ol",
        "outputId": "bcc2452c-b6cf-41a3-a3a9-9fc93adc7561"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "\n",
        "print(datetime.now())\n",
        "spark.sparkContext"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 39
        },
        "id": "Vu_ZRU1-K3LD",
        "outputId": "3fc4c0b3-67d8-4af7-cfff-c0d7ac013e57"
      },
      "outputs": [],
      "source": [
        "# from google.colab import files\n",
        "# uploaded = files.upload()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HiQNRRUdMrUY",
        "outputId": "c6652c61-547a-40b8-a5ab-f00796a72cec"
      },
      "outputs": [],
      "source": [
        "# import os\n",
        "# print(os.listdir())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pGEpkiDVF9ol",
        "outputId": "9983b0fb-ddfa-4842-f0c6-1b0a01c78811"
      },
      "outputs": [],
      "source": [
        "# import json\n",
        "\n",
        "# with open(\"/home/tanvi/Documents/GitRepo/automatic-system/etl/data/weather.json\", \"r\") as opfile:\n",
        "#     data = json.load(opfile)\n",
        "\n",
        "# print(data)\n",
        "\n",
        "# with open(\"/home/tanvi/Documents/GitRepo/automatic-system/etl/data/weather_new.json\", \"w\") as f:\n",
        "#     for record in data:\n",
        "#         f.write(json.dumps(record) + \"\\n\")  # âœ… Writes each object on a new line.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OdX_QcS7F9om"
      },
      "outputs": [],
      "source": [
        "# df = spark.read.option(\"multiLine\", True).json(\"/content/weather_20250224.json\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FFIiFsTmF9om",
        "outputId": "71a76fb5-c90d-494c-da15-9a37901dc655"
      },
      "outputs": [],
      "source": [
        "# df.printSchema()\n",
        "# df.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DcYV9E6jF9on",
        "outputId": "590f4612-3d07-4aae-ba1e-43e3ba95a58d"
      },
      "outputs": [],
      "source": [
        "# !ls -ltr /home/tanvi/Documents/GitRepo/automatic-system/etl/data/weather_deindent.json\n",
        "#!chmod 777 /home/tanvi/Documents/GitRepo/automatic-system/etl/data/weather.json\n",
        "#cat /home/tanvi/Documents/GitRepo/automatic-system/etl/data/weather.json | python -m json.tools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C8KSuiMrF9on",
        "outputId": "d2b7dcda-2ab7-48f4-820a-092cf89b4e94"
      },
      "outputs": [],
      "source": [
        "# from pyspark.sql import SparkSession\n",
        "# from pyspark.sql.functions import *  # Optional: to use SQL functions like col(), lit(), etc.\n",
        "\n",
        "# df.show()\n",
        "\n",
        "# df.createOrReplaceTempView(\"weather_json\")\n",
        "# query = \"SELECT * FROM weather_json\"\n",
        "# result = spark.sql(query)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vxPlSKSEF9on"
      },
      "outputs": [],
      "source": [
        "# from pyspark.sql import SparkSession\n",
        "# from pyspark.sql.functions import get_json_object, col\n",
        "\n",
        "# result = df.select( \"location\"\n",
        "    # get_json_object(\"location\", \"$.name\").alias(\"name\")\n",
        "    # )\n",
        "\n",
        "# result.show(truncate=False)\n",
        "\n",
        "# newdf = df.select(\"location\", \"current\")\n",
        "\n",
        "# result.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OekRv_jSF9oo",
        "outputId": "dd17a700-df49-4869-f65a-4669db2d57dc"
      },
      "outputs": [],
      "source": [
        "\n",
        "# data = [\n",
        "#     (\"1\", \"\"\"{\"name\": \"John\", \"age\": 30, \"address\": {\"city\": \"New York\", \"zip\": \"10001\"}, \"phones\": [{\"type\": \"home\", \"number\": \"212-555-1234\"}, {\"type\": \"work\", \"number\": \"646-555-5678\"}]}\"\"\"),\n",
        "#     (\"2\", \"\"\"{\"name\": \"Jane\", \"age\": 25, \"address\": {\"city\": \"Boston\", \"zip\": \"02108\"}, \"phones\": [{\"type\": \"mobile\", \"number\": \"617-555-4321\"}]}\"\"\")\n",
        "# ]\n",
        "\n",
        "# samdf = spark.createDataFrame(data, [\"id\", \"json_data\"])\n",
        "\n",
        "# # Extract various fields\n",
        "# result = samdf.select(\n",
        "#     \"id\",\n",
        "#     get_json_object(\"json_data\", \"$.name\").alias(\"name\"),\n",
        "#     get_json_object(\"json_data\", \"$.age\").alias(\"age\"),\n",
        "#     get_json_object(\"json_data\", \"$.address.city\").alias(\"city\"),\n",
        "#     get_json_object(\"json_data\", \"$.phones[0].number\").alias(\"first_phone\")\n",
        "# )\n",
        "\n",
        "# # result.show(truncate=False)\n",
        "# samdf.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LNUA7zJcaO5G",
        "outputId": "670cc32d-e2f6-466a-d475-211a339729a1"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "api_dict = {\n",
        "\"API_KEY\": \"c2fe5ebd74734989a33163320252302\",\n",
        "\"BASE_URL\": \"http://api.weatherapi.com/v1/forecast.json\",\n",
        "}\n",
        "\n",
        "params= {\"key\":api_dict[\"API_KEY\"], \"q\": \"08854\", \"days\": \"1\", \"aqi\": \"no\", \"alerts\": \"no\"}\n",
        "response = requests.get(api_dict[\"BASE_URL\"], params=params)\n",
        "weather_data = response.json()\n",
        "print(weather_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from json import dumps\n",
        "from pathlib import Path\n",
        "base = \"/home/tanvi/Documents/GitRepo/automatic-system/etl\"\n",
        "json_file_path = Path(base).absolute().joinpath(\"data\", \"weather\", f\"weather_{datetime.today().strftime('%Y%m%d')}.json\")\n",
        "\n",
        "with open(json_file_path, \"w\") as writej:\n",
        "    writej.write(dumps(weather_data, indent=2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "usN9qY8krEZ1"
      },
      "outputs": [],
      "source": [
        "postgres_url = 'jdbc:postgresql://localhost:5432/postgres'\n",
        "\n",
        "postgres_properties = {\n",
        "    'user': 'postgres',\n",
        "    'password': 'myPassword',\n",
        "    'driver': 'org.postgresql.Driver'}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0eV4GJbavpdT"
      },
      "outputs": [],
      "source": [
        "import uuid\n",
        "\n",
        "single_uuid = uuid.uuid4()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SOPcHK8xb-2_",
        "outputId": "aec460f9-6f78-4831-d852-1f2be01a0fd8"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.functions import lit\n",
        "location_list = [weather_data['location']]\n",
        "df_l = spark.createDataFrame(location_list)\n",
        "df_l = df_l.withColumn(\"process_uuid\", lit(str(single_uuid)))\n",
        "df_l = df_l.withColumn(\"zipcode\", lit(\"08854\"))\n",
        "df_l.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "6HxTm7ectfO6",
        "outputId": "6d646ddd-0def-4cd5-9194-4e44297cbc58"
      },
      "outputs": [],
      "source": [
        "df_l = df_l.select(\"name\",\"region\",\"country\",\"lat\",\"lon\",\"tz_id\",\"localtime_epoch\",\"localtime\",\"process_uuid\",\"zipcode\")\n",
        "df_l = df_l.withColumnRenamed(\"name\", \"city_name\") \\\n",
        "           .withColumnRenamed(\"lat\", \"latitude\") \\\n",
        "           .withColumnRenamed(\"lon\", \"longitude\") \\\n",
        "           .withColumnRenamed(\"tz_id\", \"timezone_id\") \\\n",
        "           .withColumnRenamed(\"localtime_epoch\", \"local_time_epoch\") \\\n",
        "           .withColumnRenamed(\"localtime\", \"local_time\")\n",
        "\n",
        "df_l.write.jdbc(\n",
        "    url=postgres_url,\n",
        "    table=\"stage.location\",\n",
        "    mode=\"append\",\n",
        "    properties=postgres_properties\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YcxbZpbGfpRE",
        "outputId": "445a90bb-8d03-4dd7-da82-cd71a0c55b67"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.functions import col\n",
        "\n",
        "currently_list = [weather_data['current']]\n",
        "df_c = spark.createDataFrame(currently_list)\n",
        "df_cf = df_c.selectExpr(\"last_updated_epoch\",\"last_updated\",\"temp_c\",\"temp_f\",\"is_day\",\"wind_mph\",\"wind_kph\",\"wind_degree\",\"wind_dir\",\"pressure_mb\",\"pressure_in\",\"precip_mm\",\"precip_in\",\"humidity\",\"cloud\",\"feelslike_c\",\"feelslike_f\",\"windchill_c\",\"windchill_f\",\"heatindex_c\",\"heatindex_f\",\"dewpoint_c\",\"dewpoint_f\",\"vis_km\",\"vis_miles\",\"uv\",\"gust_mph\",\"gust_kph\",\"condition.text as condition_text\",\"condition.icon as condition_icon\",\"condition.code as condition_code\")\n",
        "df_cf = df_cf.withColumn(\"process_uuid\", lit(str(single_uuid)))\n",
        "df_cf = df_cf.withColumn(\"zipcode\", lit(\"08854\"))\n",
        "df_cf = df_cf.withColumn(\"last_updated\", col(\"last_updated\").cast(\"timestamp\"))\n",
        "df_cf.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_cf = df_cf.select(\"last_updated_epoch\",\"last_updated\",\"temp_c\",\"temp_f\",\"is_day\",\"wind_mph\",\"wind_kph\",\"wind_degree\",\"wind_dir\",\"pressure_mb\",\"pressure_in\",\"precip_mm\",\"precip_in\",\"humidity\",\"cloud\",\"feelslike_c\",\"feelslike_f\",\"windchill_c\",\"windchill_f\",\"heatindex_c\",\"heatindex_f\",\"dewpoint_c\",\"dewpoint_f\",\"vis_km\",\"vis_miles\",\"uv\",\"gust_mph\",\"gust_kph\",\"process_uuid\",\"zipcode\",\"condition_text\",\"condition_icon\",\"condition_code\")\n",
        "df_cf.write.jdbc(url=postgres_url, table=\"stage.currently\",mode=\"append\",properties=postgres_properties)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A1D0zj-rf9GP",
        "outputId": "edd9439c-6a46-41bd-d89d-722c2669c5ef"
      },
      "outputs": [],
      "source": [
        "daily_list = [weather_data['forecast']['forecastday'][0]['day']]\n",
        "df_d = spark.createDataFrame(daily_list)\n",
        "df_df = df_d.selectExpr(\"maxtemp_c\",\"maxtemp_f\",\"mintemp_c\",\"mintemp_f\",\"avgtemp_c\",\"avgtemp_f\",\"maxwind_mph\",\"maxwind_kph\",\"totalprecip_mm\",\"totalprecip_in\",\"totalsnow_cm\",\"avgvis_km\",\"avgvis_miles\",\"avghumidity\",\"daily_will_it_rain\",\"daily_chance_of_rain\",\"daily_will_it_snow\",\"daily_chance_of_snow\",\"uv\",\"condition.text as condition_text\",\"condition.icon as condition_icon\",\"condition.code as condition_code\")\n",
        "df_df = df_df.withColumn(\"process_uuid\", lit(str(single_uuid)))\n",
        "df_df = df_df.withColumn(\"zipcode\", lit(\"08854\"))\n",
        "df_df.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_df = df_df.select(\"maxtemp_c\",\"maxtemp_f\",\"mintemp_c\",\"mintemp_f\",\"avgtemp_c\",\"avgtemp_f\",\"maxwind_mph\",\"maxwind_kph\",\"totalprecip_mm\",\"totalprecip_in\",\"totalsnow_cm\",\"avgvis_km\",\"avgvis_miles\",\"avghumidity\",\"daily_will_it_rain\",\"daily_chance_of_rain\",\"daily_will_it_snow\",\"daily_chance_of_snow\",\"uv\",\"process_uuid\",\"zipcode\",\"condition_text\",\"condition_icon\",\"condition_code\")\n",
        "df_df.write.jdbc(url=postgres_url,table=\"stage.daily\",mode=\"append\",properties=postgres_properties)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385
        },
        "id": "-b-DuEWll7C0",
        "outputId": "fb03801a-c539-43b2-f12c-cc848f10ab0a"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.types import *\n",
        "\n",
        "hourly_list = weather_data['forecast']['forecastday'][0]['hour']\n",
        "date_var = weather_data['forecast']['forecastday'][0]['date']\n",
        "epoch_var = weather_data['forecast']['forecastday'][0]['date_epoch']\n",
        "\n",
        "schema = StructType([\n",
        "    StructField(\"time_epoch\", LongType(), True),\n",
        "    StructField(\"time\", StringType(), True),\n",
        "    StructField(\"temp_c\", DoubleType(), True),\n",
        "    StructField(\"temp_f\", DoubleType(), True),\n",
        "    StructField(\"is_day\", DoubleType(), True),\n",
        "    StructField(\"wind_mph\", DoubleType(), True),\n",
        "    StructField(\"wind_kph\", DoubleType(), True),\n",
        "    StructField(\"wind_degree\", DoubleType(), True),\n",
        "    StructField(\"wind_dir\", StringType(), True),\n",
        "    StructField(\"pressure_mb\", DoubleType(), True),\n",
        "    StructField(\"pressure_in\", DoubleType(), True),\n",
        "    StructField(\"precip_mm\", DoubleType(), True),\n",
        "    StructField(\"precip_in\", DoubleType(), True),\n",
        "    StructField(\"snow_cm\", DoubleType(), True),\n",
        "    StructField(\"humidity\", DoubleType(), True),\n",
        "    StructField(\"cloud\", DoubleType(), True),\n",
        "    StructField(\"feelslike_c\", DoubleType(), True),\n",
        "    StructField(\"feelslike_f\", DoubleType(), True),\n",
        "    StructField(\"windchill_c\", DoubleType(), True),\n",
        "    StructField(\"windchill_f\", DoubleType(), True),\n",
        "    StructField(\"heatindex_c\", DoubleType(), True),\n",
        "    StructField(\"heatindex_f\", DoubleType(), True),\n",
        "    StructField(\"dewpoint_c\", DoubleType(), True),\n",
        "    StructField(\"dewpoint_f\", DoubleType(), True),\n",
        "    StructField(\"will_it_rain\", DoubleType(), True),\n",
        "    StructField(\"chance_of_rain\", DoubleType(), True),\n",
        "    StructField(\"will_it_snow\", DoubleType(), True),\n",
        "    StructField(\"chance_of_snow\", DoubleType(), True),\n",
        "    StructField(\"vis_km\", DoubleType(), True),\n",
        "    StructField(\"vis_miles\", DoubleType(), True),\n",
        "    StructField(\"gust_mph\", DoubleType(), True),\n",
        "    StructField(\"gust_kph\", DoubleType(), True),\n",
        "    StructField(\"uv\", DoubleType(), True),\n",
        "    StructField(\"condition\", StructType([\n",
        "        StructField(\"text\", StringType(), True),\n",
        "        StructField(\"icon\", StringType(), True),\n",
        "        StructField(\"code\", StringType(), True)\n",
        "    ]), True),\n",
        "])\n",
        "exclude_columns = {\"time_epoch\", \"condition\"}\n",
        "hourly_list = [\n",
        "    {key: float(value) if isinstance(value, int) and key not in exclude_columns else value \n",
        "     for key, value in row.items()}\n",
        "    for row in hourly_list\n",
        "]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_h = spark.createDataFrame(hourly_list, schema=schema)\n",
        "df_hf = df_h.selectExpr(\"time_epoch\",\"time\",\"temp_c\",\"temp_f\",\"is_day\",\"wind_mph\",\"wind_kph\",\"wind_degree\",\"wind_dir\",\"pressure_mb\",\"pressure_in\",\"precip_mm\",\"precip_in\",\"snow_cm\",\"humidity\",\"cloud\",\"feelslike_c\",\"feelslike_f\",\"windchill_c\",\"windchill_f\",\"heatindex_c\",\"heatindex_f\",\"dewpoint_c\",\"dewpoint_f\",\"will_it_rain\",\"chance_of_rain\",\"will_it_snow\",\"chance_of_snow\",\"vis_km\",\"vis_miles\",\"gust_mph\",\"gust_kph\",\"uv\",\"condition.text as condition_text\",\"condition.icon as condition_icon\",\"condition.code as condition_code\")\n",
        "df_hf = df_hf.withColumn(\"date\", lit(date_var))\n",
        "df_hf = df_hf.withColumn(\"date_epoch\", lit(epoch_var))\n",
        "df_hf = df_hf.withColumn(\"process_uuid\", lit(str(single_uuid)))\n",
        "df_hf = df_hf.withColumn(\"zipcode\", lit(\"08854\"))\n",
        "df_hf = df_hf.withColumn(\"time\", col(\"time\").cast(\"timestamp\"))\n",
        "df_hf = df_hf.withColumn(\"date\", col(\"date\").cast(\"date\"))\n",
        "df_hf.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_hf = df_hf.select(\"time_epoch\",\"time\",\"temp_c\",\"temp_f\",\"is_day\",\"wind_mph\",\"wind_kph\",\"wind_degree\",\"wind_dir\",\"pressure_mb\",\"pressure_in\",\"precip_mm\",\"precip_in\",\"snow_cm\",\"humidity\",\"cloud\",\"feelslike_c\",\"feelslike_f\",\"windchill_c\",\"windchill_f\",\"heatindex_c\",\"heatindex_f\",\"dewpoint_c\",\"dewpoint_f\",\"will_it_rain\",\"chance_of_rain\",\"will_it_snow\",\"chance_of_snow\",\"vis_km\",\"vis_miles\",\"gust_mph\",\"gust_kph\",\"uv\",\"condition_text\",\"condition_icon\",\"condition_code\",\"date\",\"date_epoch\",\"process_uuid\",\"zipcode\")\n",
        "df_hf.write.jdbc(url=postgres_url,table=\"stage.hourly\",mode=\"append\",properties=postgres_properties)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "spark.stop()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
